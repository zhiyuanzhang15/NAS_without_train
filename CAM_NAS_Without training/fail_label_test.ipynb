{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchcam.utils import overlay_mask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import os\n",
    "import shutil\n",
    "from d2l import torch as d2l\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = r'C:\\AI_project\\data\\ImageNet'\n",
    "def read_csv_labels(fname):\n",
    "    \"\"\"读取 fname 来给标签字典返回一个文件名\"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = [l.rstrip().split(' ')[1] for l in lines]\n",
    "    return tokens\n",
    "\n",
    "def read_csv_labels_1(fname):\n",
    "    \"\"\"读取 fname 来给标签字典返回一个文件名\"\"\"\n",
    "    with open(fname, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = [l.rstrip() for l in lines]\n",
    "    return tokens\n",
    "\n",
    "labels_2 = read_csv_labels(os.path.join(data_dir,'val.txt'))\n",
    "labels_1 = read_csv_labels_1(os.path.join(data_dir,'result.txt'))\n",
    "labels = read_csv_labels_1(os.path.join(data_dir,'ILSVRC2012_validation_ground_truth.txt'))\n",
    "files = sorted(list(set(labels)))\n",
    "np_labels = np.array(labels_2, dtype=int)\n",
    "np_labels_1 = np.array(labels, dtype=int)\n",
    "result_1 = np_labels - np_labels_1 \n",
    "(result_1==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =os.listdir(os.path.join(data_dir, 'validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyfile(filename, target_dir):\n",
    "    \"\"\"将文件复制到目标目录\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    shutil.copy(filename, target_dir)\n",
    "\n",
    "def reorg_valid(data_dir, labels):\n",
    "    for i in range(len(labels)):\n",
    "        label = labels[i]\n",
    "        file = filename[i]\n",
    "        fname = os.path.join(data_dir, 'validation', file)\n",
    "        copyfile(fname, os.path.join(data_dir, 'valid',label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorg_valid(data_dir=data_dir, labels= labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([256,256]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n",
    "                                     [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = torchvision.datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'valid'), transform=transform_test)\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size=10, shuffle=False, drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as tm\n",
    "\n",
    "devices = d2l.try_all_gpus()\n",
    "net_1 = tm.alexnet(pretrained=True).eval()\n",
    "preds = []\n",
    "test_label = []\n",
    "i = 0\n",
    "right = 0\n",
    "wrong = 0\n",
    "for X, y in valid_iter:\n",
    "    y_hat = net_1(X)\n",
    "    preds.extend(y_hat.argmax(dim=1).type(torch.int32).cpu().numpy())\n",
    "    test_label.extend(y.numpy())\n",
    "    '''if y_hat.argmax(dim=1).type(torch.int32).cpu().numpy() == y.numpy():\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong += 1'''\n",
    "\n",
    "    i += 1\n",
    "    if i == 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1925"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_preds = np.array(preds)\n",
    "np_testlabel = np.array(test_label)\n",
    "result = np_preds - np_testlabel\n",
    "(result == 0).sum() / len(preds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dd332e029b44e3cdae0bc1e0f889432ab10c991d94ce208a100786ff3ed8f98"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
